{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import seaborn as sns\n",
    "import email\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"archive (6)/emails.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841cc070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddf0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[1]['message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from email import message_from_string\n",
    "message = df.loc[1]['message']\n",
    "a = message_from_string(message)\n",
    "\n",
    "a.items()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get('Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_payload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64281ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field(field, messages):\n",
    "    return [email.message_from_string(message).get(field) for message in messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = get_field(\"Date\", df['message'])\n",
    "df['subject'] = get_field(\"Subject\", df['message'])\n",
    "df['X-Folder'] = get_field(\"X-Folder\", df['message'])\n",
    "df['X-From'] = get_field(\"X-From\", df['message'])\n",
    "df['X-To'] = get_field(\"X-To\", df['message'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40252565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body'] = [email.message_from_string(msg).get_payload() for msg in df['message']]\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ffece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8666d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employee'] = [path.split(\"/\")[0] for path in df['file']]\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afcd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_emails = df['X-Folder'].value_counts().head(20).reset_index()\n",
    "unique_emails.columns = ['folder_name', 'count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "def change_type(dates):\n",
    "    return [parser.parse(date).strftime(\"%d-%m-%Y %H:%M:%S\") for date in dates]\n",
    "\n",
    "\n",
    "df['date'] = change_type(df['date'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_folder(folders):\n",
    "    return [np.nan if folder is None or folder == \"\" else folder.split(\"\\\\\")[-1].lower() for folder in folders]\n",
    "\n",
    "df['X-Folder'] = preprocess_folder(df['X-Folder'])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique Foldes: \", len(df['X-Folder'].unique()))\n",
    "df['X-Folder'].unique()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_empty_with_nan(subject):\n",
    "    return [np.nan if val == \"\" else val for val in subject]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d55a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject'] = replace_empty_with_nan(df['subject'])\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5edcbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30491b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(), df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd090b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ec588",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['file','message','date','X-From','X-To']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "pd.set_option('display.max_rows', 50)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19727577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_folders(emails, n):\n",
    "    email_count = df['X-Folder'].value_counts()\n",
    "    folders_to_keep = email_count[email_count > n].index\n",
    "    return df[df['X-Folder'].isin(folders_to_keep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "df = remove_folders(df, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748927d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['subject'] + \" \" + df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e66c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['subject','body'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55adfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = x.lower()\n",
    "    x = re.sub(r'\\n+', ' ', x)\n",
    "    x = re.sub(\"[\"+string.punctuation+\"]\", \" \", x)\n",
    "    x = re.sub(r'\\s+', ' ', x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7edbe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df.loc[:,'text'] = df.loc[:, 'text'].map(preprocess)\n",
    "\n",
    "# remove stopwords\n",
    "df.loc[:, 'text'] = df.loc[:, 'text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
    "end = time.time()\n",
    "print(\"Execution time (sec): \",(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10475912",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "email_count_dict = dict(df['X-Folder'].value_counts().sort_values()[50:70])\n",
    "selected_emails = df[df['X-Folder'].isin(email_count_dict.keys())]\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time (sec): \", execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7298d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ebe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"preprocessed.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X-Folder'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b4869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(data):\n",
    "    class_le = LabelEncoder()\n",
    "    y = class_le.fit_transform(data['X-Folder'])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['employee']\n",
    "\n",
    "data.drop(cols_to_drop, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd014f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_encoder(data)\n",
    "input_data = data['text']\n",
    "input_data = input_data.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "vectorizer = CountVectorizer(min_df=5, max_features=5000)\n",
    "X = vectorizer.fit_transform(input_data)\n",
    "end = time.time()\n",
    "print(\"Execution time (sec): \",(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "X = X.toarray()\n",
    "print(\"X.shape: \",X.shape)\n",
    "end = time.time()\n",
    "print(\"Execution time (sec): \",(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data = {\n",
    "    'Algorithm': ['Gaussian NB', 'Multinomial NB','Decision Tree','SVM'],\n",
    "    'BoW': ''\n",
    "}\n",
    "f1_df = pd.DataFrame(f1_data)\n",
    "\n",
    "jaccard_data = {\n",
    "    'Algorithm': ['Gaussian NB', 'Multinomial NB', 'Decision Tree','SVM'],\n",
    "    'BoW': ''\n",
    "}\n",
    "jacc_df = pd.DataFrame(jaccard_data)\n",
    "\n",
    "acc_data = {\n",
    "    'Algorithm': ['Gaussian NB', 'Multinomial NB','Decision Tree','SVM'],\n",
    "    'BoW': ''\n",
    "}\n",
    "acc_df = pd.DataFrame(acc_data)\n",
    "acc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af655ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GaussianNB(), MultinomialNB(), DecisionTreeClassifier(), LinearSVC()]\n",
    "\n",
    "names = [\"Gaussian NB\", \"Multinomial NB\", \"Decision Tree\", \"SVM\"]\n",
    "\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "exec_times = []\n",
    "\n",
    "for model, name in zip(models, names):\n",
    "    print(name)\n",
    "    start = time.time()\n",
    "    scoring = {\n",
    "        'acc': 'accuracy',\n",
    "        'f1_mac': 'f1_macro',\n",
    "    }\n",
    "    try:\n",
    "        scores = cross_validate(model, X.toarray(), y, cv=10, n_jobs=4, scoring=scoring)\n",
    "        training_time = (time.time() - start)\n",
    "        print(\"accuracy: \", scores['test_acc'].mean())\n",
    "        print(\"f1_score: \", scores['test_f1_mac'].mean())\n",
    "        print(\"time (sec): \", training_time)\n",
    "        print(\"\\n\")\n",
    "         \n",
    "        acc_scores.append(scores['test_acc'].mean())\n",
    "        f1_scores.append(scores['test_f1_mac'].mean())\n",
    "        exec_times.append(training_time)\n",
    "    except TypeError as e:\n",
    "        print(\"Error:\", e)\n",
    "        continue\n",
    "    \n",
    "acc_df['BoW'] = acc_scores\n",
    "f1_df['BoW'] = f1_scores\n",
    "acc_df['time'] = exec_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922da69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df.to_csv(\"accuracy.csv\", index=False)\n",
    "f1_df.to_csv(\"f1_score.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f9f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "vectorizer = CountVectorizer(min_df=5, max_features=5000, ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(input_data)\n",
    "\n",
    "X = X.toarray()\n",
    "print(\"X.shape: \",X.shape)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time (sec): \",(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50348c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c861e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Embedding, Input, Conv1D, MaxPooling1D\n",
    "from keras.layers import Concatenate, Input, Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"archive (7)/GoogleNews-vectors-negative300.bin\"\n",
    "\n",
    "start_time = time.monotonic()\n",
    "google_embeddings = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "end_time = time.monotonic()\n",
    "\n",
    "load_time = end_time - start_time\n",
    "print(f\"Load time (seconds): {load_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72841081",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = \"archive (7)/glove.6B.300d.txt\"\n",
    "glove_word2vec_file = \"glove.6B.300d.txt.word2vec\"\n",
    "\n",
    "glove2word2vec(glove_file, glove_word2vec_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b425c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "glove_embeddings = KeyedVectors.load_word2vec_format(glove_word2vec_file, binary=False)\n",
    "\n",
    "print(\"Load time (seconds): \", (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"preprocessed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n",
    "    class_le = LabelEncoder()\n",
    "    y = class_le.fit_transform(df['X-Folder'])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5279da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = label_encoder(df)\n",
    "corpus = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f2ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(corpus, y, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "\n",
    "for sent in corpus:\n",
    "    tokenize_word = word_tokenize(sent)\n",
    "    for word in tokenize_word:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05eca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set(all_words)\n",
    "print(\"Unique words: \",len(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(corpus)\n",
    "train_encoded_docs = t.texts_to_sequences(X_train)\n",
    "test_encoded_docs = t.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d412ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = lambda doc: len(word_tokenize(doc))\n",
    "longest_doc = max(corpus, key=word_count)\n",
    "length_longest_doc = len(word_tokenize(longest_doc))\n",
    "length_longest_doc = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c11f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded_docs = pad_sequences(train_encoded_docs, length_longest_doc, padding='post')\n",
    "test_padded_docs = pad_sequences(test_encoded_docs, length_longest_doc, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79234f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train, 20)\n",
    "Y_test = to_categorical(y_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0477d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for doc in corpus:\n",
    "    li = list(doc.split())\n",
    "    docs.append(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = Word2Vec(docs, vector_size=300, window=5, min_count=1, workers=4, sg=0)\n",
    "print(model)\n",
    "model.save(\"email_embeddings.bin\")\n",
    "\n",
    "print(\"Training time (seconds): \", (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124145b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "filename = \"email_embeddings.bin\"\n",
    "\n",
    "email_embeddings = Word2Vec.load(filename)\n",
    "\n",
    "print(\"Load time (seconds): \", (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c62eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(email_embeddings.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f174f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "count = 0\n",
    "\n",
    "for word, i in t.word_index.items():\n",
    "    if word in google_embeddings.index_to_key:\n",
    "        embedding_vector = google_embeddings[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    elif word in email_embeddings.wv.key_to_index:\n",
    "        embedding_vector = email_embeddings.wv.get_vector(word) # use get_vector() method\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    else: \n",
    "        count += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of words not present in email_embeddings: \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92868b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18838a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(length_longest_doc, vocab_size, embedding_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length_longest_doc,))\n",
    "    embedding1 = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], trainable=False)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "\n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length_longest_doc,))\n",
    "    embedding2 = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], trainable=False)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "\n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length_longest_doc,))\n",
    "    embedding3 = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], trainable=False)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "\n",
    "    # merge\n",
    "    merged = layers.concatenate([flat1, flat2, flat3])\n",
    "    \n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(20, activation='softmax')(dense1)\n",
    "\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "    plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model_b(length_longest_doc, vocab_size, embedding_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length_longest_doc,))\n",
    "    embedding1 = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], trainable=False)(inputs1)\n",
    "    lstm1_a = LSTM(256, dropout=0.5, return_sequences=True)(embedding1)\n",
    "    lstm1_b = LSTM(128, dropout=0.5)(lstm1_a)\n",
    "    flat1 = Flatten()(lstm1_b)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length_longest_doc,))\n",
    "    embedding2 = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], trainable=False)(inputs2)\n",
    "    lstm2_a = LSTM(256, dropout=0.5, return_sequences=True)(embedding2)\n",
    "    lstm2_b = LSTM(128, dropout=0.5)(lstm2_a)\n",
    "    flat2 = Flatten()(lstm2_b)\n",
    "    \n",
    "    # merge\n",
    "    merge = concatenate([flat1, flat2])\n",
    "    \n",
    "    # interpretation\n",
    "    #dense1 = Dense(10, activation='relu')(merge)\n",
    "    outputs = Dense(20, activation='softmax')(merge)\n",
    "    \n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # print model summary\n",
    "    model.summary()\n",
    "    #plot_model(model, show_shapes=True, to_file='model.png')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07037e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e17201",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = define_model_b(length_longest_doc, vocab_size, 300)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4, min_delta=0.001)\n",
    "\n",
    "history = model.fit([train_padded_docs, train_padded_docs], np.array(Y_train), epochs=50, batch_size=16, validation_split=0.1, callbacks=[es])\n",
    "\n",
    "model.save(\"model1.h5\")\n",
    "print(\"Training time (minutes): \", (round((time.time() - start)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc3816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_train_eval = model2.evaluate([train_padded_docs,train_padded_docs,train_padded_docs], np.array(Y_train), verbose=0)\n",
    "model2_test_eval = model2.evaluate([test_padded_docs, test_padded_docs, test_padded_docs], np.array(Y_test), verbose=0)\n",
    "\n",
    "print(\"Train Accuracy: {:0.3f}    Loss: {:0.3f}\".format(model2_train_eval[1], model2_train_eval[0]))\n",
    "print(\"Test Accuracy:  {:0.3f}    Loss: {:0.3f}\".format(model2_test_eval[1], model2_test_eval[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014a725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_vi]",
   "language": "python",
   "name": "conda-env-data_vi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
